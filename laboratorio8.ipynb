{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8086f3be-c8f0-4720-8969-149fa54e9143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Laboratorio 8 - Transformaciones con Spark\n",
    "\n",
    "#### Edwin Ortega 22305\n",
    "#### Esteban Zambrano 22119\n",
    "#### Diego García 22404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52c12913-162e-413d-b52f-4c24f27629a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### Carga de Datos y Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8122b58-bde9-4955-90c4-f769567bb706",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "##### Instalación a tener en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a87e085-0922-4fb9-a808-b3210d6b6c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85368396-49dd-4df4-8243-793560a99858",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### Convertir Excel a un CSV por hoja\n",
    "##### Rutas, imports y utilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "088d8e6a-1443-493f-ad28-29ed8a6a8d2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Se debe mover los excel en la carpeta 'Data' a un volumen de databricks. Se deben cambiar las rutas a las suyas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bd0a2b4-8a49-4876-bb09-143f99914857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Cambiar esto a su volumen\n",
    "BASE_DIR = \"/Volumes/workspace/default/lab8-ds\"\n",
    "\n",
    "SUBFOLDERS = [\"fallecidos-lesionados\", \"hechos\", \"vehiculos\"]\n",
    "OUTPUT_ROOT = os.path.join(BASE_DIR, \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323dd6c1-c628-44db-9473-580f123d4c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "for sub in SUBFOLDERS:\n",
    "    os.makedirs(os.path.join(OUTPUT_ROOT, sub), exist_ok=True)\n",
    "\n",
    "print(\"Base:\", BASE_DIR)\n",
    "print(\"Salida:\", OUTPUT_ROOT)\n",
    "print(\"Subcarpetas:\", SUBFOLDERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2561ea-5bfc-48a2-8a42-ed2c402fc4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "manifest, errors = [], []\n",
    "\n",
    "for sub in SUBFOLDERS:\n",
    "    in_dir = Path(BASE_DIR) / sub\n",
    "    out_dir = Path(OUTPUT_ROOT) / sub\n",
    "\n",
    "    for f in sorted(in_dir.iterdir()):\n",
    "        if not f.is_file():\n",
    "            continue\n",
    "        if f.suffix.lower() not in {\".xlsx\", \".xls\"}:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Lee SOLO la primera hoja\n",
    "            df = pd.read_excel(f, sheet_name=0)\n",
    "            # Nombre base del archivo + .csv\n",
    "            csv_name = f.with_suffix(\".csv\").name\n",
    "            csv_path = out_dir / csv_name\n",
    "\n",
    "            # Guarda CSV sin índice\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            manifest.append((sub, str(f), str(csv_path)))\n",
    "        except Exception as e:\n",
    "            errors.append((str(f), repr(e)))\n",
    "\n",
    "print(f\"CSV generados: {len(manifest)}\")\n",
    "if errors:\n",
    "    print(f\"Archivos con error: {len(errors)} (muestra 5)\")\n",
    "    for p, err in errors[:5]:\n",
    "        print(\"-\", p, \"->\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f0b96fc-3146-4991-824a-8aed9a555ef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76056f4-1903-4aac-8c72-b7961e2d7685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INPUT_ROOT  = Path(BASE_DIR) / \"csv\"\n",
    "\n",
    "# Recolecta rutas de todos los CSV\n",
    "csv_files = []\n",
    "for sub in SUBFOLDERS:\n",
    "    folder = INPUT_ROOT / sub\n",
    "    if not folder.exists():\n",
    "        print(f\"⚠️ No existe: {folder}\")\n",
    "        continue\n",
    "    for f in sorted(folder.iterdir()):\n",
    "        if f.is_file() and f.suffix.lower() == \".csv\":\n",
    "            csv_files.append((sub, f))\n",
    "\n",
    "print(f\"Archivos CSV encontrados: {len(csv_files)}\")\n",
    "for i, (sub, f) in enumerate(csv_files[:10], start=1):\n",
    "    print(f\"{i:02d}. [{sub}] {f.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d466f89f-047c-43bf-bae2-5de0ab8ba0c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estandarización de datos\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def strip_accents_lower(text: str) -> str:\n",
    "    \"\"\"Convierte a minúsculas, elimina acentos/diéresis y comprime espacios.\"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "    s = str(text).lower().strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def normalize_headers(cols):\n",
    "    \"\"\"Normaliza encabezados: minus, sin acentos, espacios->_, solo [a-z0-9_].\"\"\"\n",
    "    norm = []\n",
    "    for c in cols:\n",
    "        s = strip_accents_lower(c)\n",
    "        s = re.sub(r\"[^a-z0-9_ ]\", \"\", s)\n",
    "        s = s.replace(\" \", \"_\")\n",
    "        s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "        norm.append(s or \"col\")\n",
    "    return norm\n",
    "\n",
    "def normalize_dataframe_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Devuelve una copia con encabezados normalizados y columnas object en minus/sin acentos.\"\"\"\n",
    "    out = df.copy()\n",
    "    out.columns = normalize_headers(out.columns)\n",
    "    obj_cols = out.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    for c in obj_cols:\n",
    "        out[c] = out[c].map(strip_accents_lower)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76dcbcc-b7ce-4abf-bf85-7b0288a1babc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_data   = {}\n",
    "clean_data = {}\n",
    "\n",
    "errors = []\n",
    "\n",
    "for sub, f in csv_files:\n",
    "    try:\n",
    "        # Detecta separador automáticamente; cae a coma si falla\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep=None, engine=\"python\", encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "        except Exception:\n",
    "            df = pd.read_csv(f, encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "\n",
    "        df_clean = normalize_dataframe_text(df)\n",
    "\n",
    "        key = (sub, f.name)\n",
    "        raw_data[key] = df\n",
    "        clean_data[key] = df_clean\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append((str(f), repr(e)))\n",
    "\n",
    "print(f\"DataFrames cargados: {len(raw_data)} | Normalizados: {len(clean_data)}\")\n",
    "if errors:\n",
    "    print(f\"⚠️ Errores en {len(errors)} archivos (muestra 5):\")\n",
    "    for p, err in errors[:5]:\n",
    "        print(\"-\", p, \"->\", err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0405f5d-7a66-4ce7-bf55-e5f1dd7358fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selección de columanas para Fallecidos/lesionados\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# columnas requeridas\n",
    "req_fall = [\"ano_ocu\",\"mes_ocu\",\"depto_ocu\",\"zona_ocu\",\"edad_per\",\"tipo_eve\",\"fall_les\"]\n",
    "\n",
    "sel_fallecidos = {}\n",
    "faltantes_fallecidos = []\n",
    "\n",
    "for (sub, fname), df in clean_data.items():\n",
    "    if sub != \"fallecidos-lesionados\":\n",
    "        continue\n",
    "\n",
    "    # detecta año desde el nombre del archivo (primer 4 dígitos)\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    anio = int(m.group(1)) if m else None\n",
    "\n",
    "    # crea columnas faltantes con \"ignorado\"\n",
    "    missing = [c for c in req_fall if c not in df.columns]\n",
    "    for c in missing:\n",
    "        df[c] = \"ignorado\"\n",
    "\n",
    "    # registra faltantes (uno por columna faltante)\n",
    "    for c in missing:\n",
    "        faltantes_fallecidos.append({\"anio\": anio, \"archivo\": fname, \"col_faltante\": c})\n",
    "\n",
    "    # deja solo las columnas requeridas en el orden pedido\n",
    "    sel = df[req_fall].copy()\n",
    "    sel_fallecidos[(sub, fname)] = sel\n",
    "\n",
    "# reporte\n",
    "reporte_fallecidos = pd.DataFrame(faltantes_fallecidos)\n",
    "display(reporte_fallecidos.sort_values([\"anio\",\"col_faltante\"]) if not reporte_fallecidos.empty \n",
    "        else pd.DataFrame(columns=[\"anio\",\"archivo\",\"col_faltante\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1608b460-4443-4e65-8fb0-2774f3ade811",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selección de columanas para hechos\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "req_hechos = [\"ano_ocu\",\"hora_ocu\",\"mes_ocu\",\"dia_sem_ocu\",\"depto_ocu\",\"tipo_eve\"]\n",
    "\n",
    "sel_hechos = {}\n",
    "faltantes_hechos = []\n",
    "\n",
    "for (sub, fname), df in clean_data.items():\n",
    "    if sub != \"hechos\":\n",
    "        continue\n",
    "\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    anio = int(m.group(1)) if m else None\n",
    "\n",
    "    missing = [c for c in req_hechos if c not in df.columns]\n",
    "    for c in missing:\n",
    "        df[c] = \"ignorado\"\n",
    "\n",
    "    for c in missing:\n",
    "        faltantes_hechos.append({\"anio\": anio, \"archivo\": fname, \"col_faltante\": c})\n",
    "\n",
    "    sel = df[req_hechos].copy()\n",
    "    sel_hechos[(sub, fname)] = sel\n",
    "\n",
    "reporte_hechos = pd.DataFrame(faltantes_hechos)\n",
    "display(reporte_hechos.sort_values([\"anio\",\"col_faltante\"]) if not reporte_hechos.empty \n",
    "        else pd.DataFrame(columns=[\"anio\",\"archivo\",\"col_faltante\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62dce7a2-1460-4e4c-816c-a0ea1b98b2ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selección de columanas para vehiculos\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "req_veh = [\"ano_ocu\",\"mes_ocu\",\"depto_ocu\",\"sexo_per\",\"tipo_veh\",\"marca_veh\",\"color_veh\",\"modelo_veh\",\"tipo_eve\"]\n",
    "\n",
    "sel_vehiculos = {}\n",
    "faltantes_vehiculos = []\n",
    "\n",
    "for (sub, fname), df in clean_data.items():\n",
    "    if sub != \"vehiculos\":\n",
    "        continue\n",
    "\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    anio = int(m.group(1)) if m else None\n",
    "\n",
    "    missing = [c for c in req_veh if c not in df.columns]\n",
    "    for c in missing:\n",
    "        df[c] = \"ignorado\"\n",
    "\n",
    "    for c in missing:\n",
    "        faltantes_vehiculos.append({\"anio\": anio, \"archivo\": fname, \"col_faltante\": c})\n",
    "\n",
    "    sel = df[req_veh].copy()\n",
    "    sel_vehiculos[(sub, fname)] = sel\n",
    "\n",
    "reporte_vehiculos = pd.DataFrame(faltantes_vehiculos)\n",
    "display(reporte_vehiculos.sort_values([\"anio\",\"col_faltante\"]) if not reporte_vehiculos.empty \n",
    "        else pd.DataFrame(columns=[\"anio\",\"archivo\",\"col_faltante\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74e995ad-6be9-4f5e-8951-99c75795d9a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "YEAR = 2019  # ← cambia el año\n",
    "\n",
    "keys_veh = [k for k in sel_vehiculos.keys() if re.search(fr\"\\b{YEAR}\\b\", k[1])]\n",
    "keys_veh = sorted(keys_veh, key=lambda x: x[1])\n",
    "\n",
    "if keys_veh:\n",
    "    sample_key = keys_veh[0]\n",
    "    print(\"Mostrando (vehiculos):\", sample_key)\n",
    "    display(sel_vehiculos[sample_key].head(10))\n",
    "else:\n",
    "    print(f\"No se encontró archivo de vehiculos con año {YEAR} en el nombre.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207087fe-528d-4d0c-bee6-000a0ca2d407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estandarización de datos generales\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "YEAR_MIN, YEAR_MAX = 2013, 2020\n",
    "\n",
    "# mapas\n",
    "MES_MAP = {\n",
    "    1:\"enero\", 2:\"febrero\", 3:\"marzo\", 4:\"abril\", 5:\"mayo\", 6:\"junio\",\n",
    "    7:\"julio\", 8:\"agosto\", 9:\"septiembre\", 10:\"octubre\", 11:\"noviembre\", 12:\"diciembre\"\n",
    "}\n",
    "\n",
    "DEPTO_MAP = {\n",
    "     1:\"guatemala\",  2:\"el progreso\", 3:\"sacatepequez\", 4:\"chimaltenango\",\n",
    "     5:\"escuintla\",  6:\"santa rosa\",  7:\"solola\",       8:\"totonicapan\",\n",
    "     9:\"quetzaltenango\", 10:\"suchitepequez\", 11:\"retalhuleu\", 12:\"san marcos\",\n",
    "    13:\"huehuetenango\", 14:\"quiche\", 15:\"baja verapaz\", 16:\"alta verapaz\",\n",
    "    17:\"peten\", 18:\"izabal\", 19:\"zacapa\", 20:\"chiquimula\", 21:\"jalapa\", 22:\"jutiapa\"\n",
    "}\n",
    "\n",
    "TIPO_EVE_MAP = {\n",
    "     1:\"colision\", 2:\"choque\", 3:\"vuelco\", 4:\"caida\", 5:\"atropello\",\n",
    "     6:\"perdida de control\", 7:\"colision contra animal\", 8:\"exceso de pasaje\",\n",
    "     9:\"asfalto mojado\", 10:\"exceso de velocidad\", 11:\"desperfectos mecanicos\",\n",
    "    12:\"incendio\", 99:\"ignorado\"\n",
    "}\n",
    "\n",
    "def _apply_general_changes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # 1) \"ignorada\" -> \"ignorado\" en todas las columnas de texto\n",
    "    obj_cols = out.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    for c in obj_cols:\n",
    "        out[c] = out[c].replace(\"ignorada\", \"ignorado\")\n",
    "\n",
    "    # 2) mes_ocu numérico -> nombre\n",
    "    if \"mes_ocu\" in out.columns:\n",
    "        _num = pd.to_numeric(out[\"mes_ocu\"], errors=\"coerce\")\n",
    "        mask = _num.notna()\n",
    "        out.loc[mask, \"mes_ocu\"] = _num[mask].astype(int).map(MES_MAP).fillna(out.loc[mask, \"mes_ocu\"])\n",
    "\n",
    "    # 3) depto_ocu numérico -> nombre\n",
    "    if \"depto_ocu\" in out.columns:\n",
    "        _num = pd.to_numeric(out[\"depto_ocu\"], errors=\"coerce\")\n",
    "        mask = _num.notna()\n",
    "        out.loc[mask, \"depto_ocu\"] = _num[mask].astype(int).map(DEPTO_MAP).fillna(out.loc[mask, \"depto_ocu\"])\n",
    "\n",
    "    # 4) tipo_eve numérico -> nombre\n",
    "    if \"tipo_eve\" in out.columns:\n",
    "        _num = pd.to_numeric(out[\"tipo_eve\"], errors=\"coerce\")\n",
    "        mask = _num.notna()\n",
    "        out.loc[mask, \"tipo_eve\"] = _num[mask].astype(int).map(TIPO_EVE_MAP).fillna(out.loc[mask, \"tipo_eve\"])\n",
    "\n",
    "    return out\n",
    "\n",
    "def _year_from_filename(fname: str):\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "changed_fallecidos = {}\n",
    "changed_hechos = {}\n",
    "changed_vehiculos = {}\n",
    "\n",
    "for key, df in sel_fallecidos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "    if yr is not None and (YEAR_MIN <= yr <= YEAR_MAX):\n",
    "        changed_fallecidos[key] = _apply_general_changes(df)\n",
    "    else:\n",
    "        changed_fallecidos[key] = df\n",
    "\n",
    "for key, df in sel_hechos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "    if yr is not None and (YEAR_MIN <= yr <= YEAR_MAX):\n",
    "        changed_hechos[key] = _apply_general_changes(df)\n",
    "    else:\n",
    "        changed_hechos[key] = df\n",
    "\n",
    "for key, df in sel_vehiculos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "    if yr is not None and (YEAR_MIN <= yr <= YEAR_MAX):\n",
    "        changed_vehiculos[key] = _apply_general_changes(df)\n",
    "    else:\n",
    "        changed_vehiculos[key] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e7a08a-1bd6-423d-a756-b3a75f606b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estandarización de datos de fallecidos-lesionados\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "YEAR_MIN, YEAR_MAX = 2013, 2020\n",
    "\n",
    "def _year_from_filename(fname: str):\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "final_fallecidos = {}\n",
    "\n",
    "for key, df in changed_fallecidos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "\n",
    "    if yr is None or not (YEAR_MIN <= yr <= YEAR_MAX):\n",
    "        # fuera de rango: lo dejamos igual\n",
    "        final_fallecidos[key] = df\n",
    "        continue\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    # zona_ocu: 99 -> \"ignorado\"\n",
    "    if \"zona_ocu\" in out.columns:\n",
    "        znum = pd.to_numeric(out[\"zona_ocu\"], errors=\"coerce\")\n",
    "        out.loc[znum == 99, \"zona_ocu\"] = \"ignorado\"\n",
    "\n",
    "    # edad_per: 999 -> \"ignorado\"\n",
    "    if \"edad_per\" in out.columns:\n",
    "        ednum = pd.to_numeric(out[\"edad_per\"], errors=\"coerce\")\n",
    "        out.loc[ednum == 999, \"edad_per\"] = \"ignorado\"\n",
    "\n",
    "    # fall_les: 1 -> \"fallecido\"; 2 -> \"lesionado\"\n",
    "    if \"fall_les\" in out.columns:\n",
    "        # Maneja valores numéricos o string\n",
    "        out[\"fall_les\"] = (\n",
    "            out[\"fall_les\"]\n",
    "            .astype(str).str.strip()\n",
    "            .replace({\"1\": \"fallecido\", \"2\": \"lesionado\"})\n",
    "        )\n",
    "\n",
    "    for c in [\"zona_ocu\", \"edad_per\", \"fall_les\", \"mes_ocu\",\"depto_ocu\", \"tipo_eve\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].astype(\"string\").fillna(\"ignorado\")\n",
    "\n",
    "    final_fallecidos[key] = out\n",
    "\n",
    "# Vista rápida\n",
    "if final_fallecidos:\n",
    "    sample_key = sorted(final_fallecidos.keys(), key=lambda k: k[1])[0]\n",
    "    print(\"Mostrando (fallecidos-lesionados):\", sample_key)\n",
    "    display(final_fallecidos[sample_key].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab2a4f9e-230e-410c-bd72-bd556c26ce2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estandarización de datos de hechos\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "YEAR_MIN, YEAR_MAX = 2013, 2020\n",
    "\n",
    "def _year_from_filename(fname: str):\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# 1=lunes, 2=martes, ..., 7=domingo (sin tildes)\n",
    "DOW_MAP = {1:\"lunes\", 2:\"martes\", 3:\"miercoles\", 4:\"jueves\", 5:\"viernes\", 6:\"sabado\", 7:\"domingo\"}\n",
    "\n",
    "final_hechos = {}\n",
    "\n",
    "for key, df in changed_hechos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "\n",
    "    if yr is None or not (YEAR_MIN <= yr <= YEAR_MAX):\n",
    "        final_hechos[key] = df\n",
    "        continue\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    if \"dia_sem_ocu\" in out.columns:\n",
    "        nums = pd.to_numeric(out[\"dia_sem_ocu\"], errors=\"coerce\")\n",
    "        mask = nums.notna()\n",
    "        out.loc[mask, \"dia_sem_ocu\"] = nums[mask].astype(int).map(DOW_MAP).fillna(out.loc[mask, \"dia_sem_ocu\"])\n",
    "        # Evita problemas Arrow: homogeniza a string y rellena nulos\n",
    "        out[\"dia_sem_ocu\"] = out[\"dia_sem_ocu\"].astype(\"string\").fillna(\"ignorado\")\n",
    "\n",
    "    final_hechos[key] = out\n",
    "\n",
    "# Vista rápida\n",
    "if final_hechos:\n",
    "    sample_key = sorted(final_hechos.keys(), key=lambda k: k[1])[1]\n",
    "    print(\"Mostrando (hechos):\", sample_key)\n",
    "    display(final_hechos[sample_key].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95305ed-b921-4495-823c-cbe57e411d93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estandarización de datos de vehiculos\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Rangos\n",
    "YEAR_MIN_GENERAL, YEAR_MAX_GENERAL = 2013, 2020\n",
    "YEAR_MIN_DROP_MARCA, YEAR_MAX_DROP_MARCA = 2013, 2023\n",
    "\n",
    "def _year_from_filename(fname: str):\n",
    "    m = re.search(r\"(\\d{4})\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# Mapas (texto ya sin acentos y en minusculas)\n",
    "SEXO_MAP = {1: \"hombre\", 2: \"mujer\", 9: \"ignorado\"}\n",
    "\n",
    "TIPO_VEH_MAP = {\n",
    "     1: \"automovil\",  2: \"camioneta\",  3: \"pick_up\",      4: \"motocicleta\",\n",
    "     5: \"camion\",     6: \"cabezal\",    7: \"bus_extraurbano\", 8: \"jeep\",\n",
    "     9: \"microbus\",  10: \"taxi\",      11: \"panel\",       12: \"bus_urbano\",\n",
    "    13: \"tractor\",   14: \"moto_taxi\", 15: \"furgon\",      16: \"grua\",\n",
    "    17: \"bus_escolar\", 18: \"bicicleta\", 99: \"ignorado\"\n",
    "}\n",
    "\n",
    "COLOR_VEH_MAP = {\n",
    "     1: \"rojo\",       2: \"blanco\",     3: \"azul\",        4: \"gris\",\n",
    "     5: \"negro\",      6: \"verde\",      7: \"amarillo\",    8: \"celeste\",\n",
    "     9: \"corinto\",   10: \"cafe\",      11: \"beige\",      12: \"turquesa\",\n",
    "    13: \"marfil\",    14: \"anaranjado\", 15: \"aqua\",       16: \"morado\",\n",
    "    17: \"rosado\",    99: \"ignorado\"\n",
    "}\n",
    "\n",
    "final_vehiculos = {}\n",
    "\n",
    "for key, df in changed_vehiculos.items():\n",
    "    sub, fname = key\n",
    "    yr = _year_from_filename(fname)\n",
    "    out = df.copy()\n",
    "\n",
    "    # ---- Reglas generales para 2013–2020 ----\n",
    "    if yr is not None and (YEAR_MIN_GENERAL <= yr <= YEAR_MAX_GENERAL):\n",
    "        # sexo_per\n",
    "        if \"sexo_per\" in out.columns:\n",
    "            _num = pd.to_numeric(out[\"sexo_per\"], errors=\"coerce\")\n",
    "            mask = _num.notna()\n",
    "            out.loc[mask, \"sexo_per\"] = _num[mask].astype(int).map(SEXO_MAP).fillna(out.loc[mask, \"sexo_per\"])\n",
    "\n",
    "        # tipo_veh\n",
    "        if \"tipo_veh\" in out.columns:\n",
    "            _num = pd.to_numeric(out[\"tipo_veh\"], errors=\"coerce\")\n",
    "            mask = _num.notna()\n",
    "            out.loc[mask, \"tipo_veh\"] = _num[mask].astype(int).map(TIPO_VEH_MAP).fillna(out.loc[mask, \"tipo_veh\"])\n",
    "\n",
    "        # color_veh\n",
    "        if \"color_veh\" in out.columns:\n",
    "            _num = pd.to_numeric(out[\"color_veh\"], errors=\"coerce\")\n",
    "            mask = _num.notna()\n",
    "            out.loc[mask, \"color_veh\"] = _num[mask].astype(int).map(COLOR_VEH_MAP).fillna(out.loc[mask, \"color_veh\"])\n",
    "\n",
    "    # ---- Eliminar marca_veh para 2013–2023 ----\n",
    "    if yr is not None and (YEAR_MIN_DROP_MARCA <= yr <= YEAR_MAX_DROP_MARCA):\n",
    "        if \"marca_veh\" in out.columns:\n",
    "            out = out.drop(columns=[\"marca_veh\"])\n",
    "        elif \"modelo_veh\" in out.columns:\n",
    "            out = out.drop(columns=[\"modelo_veh\"])\n",
    "\n",
    "    # Homogeneizar tipos a string para evitar errores Arrow\n",
    "    for c in [\"sexo_per\", \"tipo_veh\", \"color_veh\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].astype(\"string\").fillna(\"ignorado\")\n",
    "\n",
    "    final_vehiculos[key] = out\n",
    "\n",
    "# Vista rápida\n",
    "if final_vehiculos:\n",
    "    sample_key = sorted(final_vehiculos.keys(), key=lambda k: k[1])[1]\n",
    "    print(\"Mostrando (vehiculos):\", sample_key)\n",
    "    display(final_vehiculos[sample_key].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87c4628-cc2c-45f6-81bf-7a3a9a9db80b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sobreescribir fallecidos/lesionados\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = \"/Volumes/workspace/default/lab8-ds\"\n",
    "OUT_ROOT = Path(BASE_DIR) / \"csv\"\n",
    "\n",
    "saved = 0\n",
    "for (sub, fname), df in final_fallecidos.items():\n",
    "    out_path = OUT_ROOT / sub / fname\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    saved += 1\n",
    "\n",
    "print(f\"CSV sobrescritos (fallecidos-lesionados): {saved}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63efef1b-06a6-437d-a4d3-5113dbdb9d02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sobreescribir hechos\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = \"/Volumes/workspace/default/lab8-ds\"\n",
    "OUT_ROOT = Path(BASE_DIR) / \"csv\"\n",
    "\n",
    "saved = 0\n",
    "for (sub, fname), df in final_hechos.items():\n",
    "    out_path = OUT_ROOT / sub / fname\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    saved += 1\n",
    "\n",
    "print(f\"CSV sobrescritos (hechos): {saved}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb90c21a-5702-41f3-a064-998aea251fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sobreescribir vehiculos\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = \"/Volumes/workspace/default/lab8-ds\"\n",
    "OUT_ROOT = Path(BASE_DIR) / \"csv\"\n",
    "\n",
    "saved = 0\n",
    "for (sub, fname), df in final_vehiculos.items():\n",
    "    out_path = OUT_ROOT / sub / fname\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    saved += 1\n",
    "\n",
    "print(f\"CSV sobrescritos (vehiculos): {saved}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36e0436e-59b3-46ba-83dc-ad82e233d5cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "##### Cargar los CSV con Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d27a562-fde4-4729-b7b4-a2dad9d84ec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === RUTA en Volume UC (NO /Workspace) ===\n",
    "DATA_DIR = \"/Volumes/workspace/default/lab8/Data\"\n",
    "\n",
    "# Hechos\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW hechos_long AS\n",
    "SELECT\n",
    "  CAST(anio AS INT)                           AS anio,\n",
    "  dim1, dim1_val, dim2, dim2_val,\n",
    "  CAST(regexp_replace(valor, '[^0-9-]', '') AS INT) AS valor,\n",
    "  lower(grupo) AS grupo,\n",
    "  cuadro, csv\n",
    "FROM read_files('{DATA_DIR}/hechos_long.csv',\n",
    "                format => 'csv', header => true)\n",
    "WHERE lower(coalesce(dim1_val,'')) <> 'total'\n",
    "  AND lower(coalesce(dim2_val,'')) <> 'total'\n",
    "\"\"\")\n",
    "\n",
    "# Vehículos\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW vehiculos_long AS\n",
    "SELECT\n",
    "  CAST(anio AS INT)                           AS anio,\n",
    "  dim1, dim1_val, dim2, dim2_val,\n",
    "  CAST(regexp_replace(valor, '[^0-9-]', '') AS INT) AS valor,\n",
    "  lower(grupo) AS grupo,\n",
    "  cuadro, csv\n",
    "FROM read_files('{DATA_DIR}/vehiculos_long.csv',\n",
    "                format => 'csv', header => true)\n",
    "WHERE lower(coalesce(dim1_val,'')) <> 'total'\n",
    "  AND lower(coalesce(dim2_val,'')) <> 'total'\n",
    "\"\"\")\n",
    "\n",
    "# Víctimas\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW victimas_long AS\n",
    "SELECT\n",
    "  CAST(anio AS INT)                           AS anio,\n",
    "  dim1, dim1_val, dim2, dim2_val,\n",
    "  CAST(regexp_replace(valor, '[^0-9-]', '') AS INT) AS valor,\n",
    "  lower(grupo) AS grupo,\n",
    "  cuadro, csv\n",
    "FROM read_files('{DATA_DIR}/victimas_long.csv',\n",
    "                format => 'csv', header => true)\n",
    "WHERE lower(coalesce(dim1_val,'')) <> 'total'\n",
    "  AND lower(coalesce(dim2_val,'')) <> 'total'\n",
    "\"\"\")\n",
    "\n",
    "# --- Chequeos rápidos ---\n",
    "display(spark.sql(\"\"\"\n",
    "SELECT 'hechos' AS tabla, COUNT(*) AS filas FROM hechos_long\n",
    "UNION ALL\n",
    "SELECT 'vehiculos', COUNT(*) FROM vehiculos_long\n",
    "UNION ALL\n",
    "SELECT 'victimas', COUNT(*) FROM victimas_long\n",
    "\"\"\"))\n",
    "\n",
    "display(spark.sql(\"SELECT DISTINCT anio FROM hechos_long ORDER BY anio\"))\n",
    "display(spark.sql(\"SELECT DISTINCT anio FROM vehiculos_long ORDER BY anio\"))\n",
    "display(spark.sql(\"SELECT DISTINCT anio FROM victimas_long ORDER BY anio\"))\n",
    "\n",
    "# Ejemplos\n",
    "display(spark.sql(\"SELECT * FROM hechos_long    ORDER BY anio, cuadro LIMIT 15\"))\n",
    "display(spark.sql(\"SELECT * FROM vehiculos_long ORDER BY anio, cuadro LIMIT 15\"))\n",
    "display(spark.sql(\"SELECT * FROM victimas_long  ORDER BY anio, cuadro LIMIT 15\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6130be8e-1b72-45c0-ad7a-46d879ce54dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Registros por tabla + show(), describe, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1908bf5-c71c-4c6b-a1d5-234d825580f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Volumes/workspace/default/lab8/Data\"\n",
    "\n",
    "# Hechos\n",
    "hechos = (spark.read.option(\"header\", True).csv(f\"{DATA_DIR}/hechos_long.csv\"))\n",
    "hechos.createOrReplaceTempView(\"hechos_long\")\n",
    "\n",
    "# Vehículos\n",
    "vehiculos = (spark.read.option(\"header\", True).csv(f\"{DATA_DIR}/vehiculos_long.csv\"))\n",
    "vehiculos.createOrReplaceTempView(\"vehiculos_long\")\n",
    "\n",
    "# Víctimas\n",
    "victimas = (spark.read.option(\"header\", True).csv(f\"{DATA_DIR}/victimas_long.csv\"))\n",
    "victimas.createOrReplaceTempView(\"victimas_long\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a5ffca-2e86-4d73-a808-4defd19f1881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(spark.catalog.tableExists(\"hechos_long\"),\n",
    "      spark.catalog.tableExists(\"vehiculos_long\"),\n",
    "      spark.catalog.tableExists(\"victimas_long\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d9001a-3e25-4405-b95d-94f9bd1b548f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Conteos\n",
    "counts = [\n",
    "    (\"hechos\",    hechos.count()),\n",
    "    (\"vehiculos\", vehiculos.count()),\n",
    "    (\"victimas\",  victimas.count()),\n",
    "]\n",
    "spark.createDataFrame(counts, [\"tabla\",\"filas\"]).show(truncate=False)\n",
    "\n",
    "# Muestras\n",
    "print(\"\\n[hechos] ejemplo:\")\n",
    "hechos.show(10, truncate=False)\n",
    "\n",
    "print(\"\\n[vehiculos] ejemplo:\")\n",
    "vehiculos.show(10, truncate=False)\n",
    "\n",
    "print(\"\\n[victimas] ejemplo:\")\n",
    "victimas.show(10, truncate=False)\n",
    "\n",
    "# Describe / summary de columnas clave\n",
    "(\n",
    "    hechos.select(\"anio\",\"dim1\",\"dim1_val\",\"dim2\",\"dim2_val\",\"valor\")\n",
    "    .describe().show()\n",
    ")\n",
    "hechos.select(\"anio\",\"valor\").summary().show()\n",
    "\n",
    "(\n",
    "    vehiculos.select(\"anio\",\"dim1\",\"dim1_val\",\"dim2\",\"dim2_val\",\"valor\")\n",
    "    .describe().show()\n",
    ")\n",
    "vehiculos.select(\"anio\",\"valor\").summary().show()\n",
    "\n",
    "(\n",
    "    victimas.select(\"anio\",\"dim1\",\"dim1_val\",\"dim2\",\"dim2_val\",\"valor\")\n",
    "    .describe().show()\n",
    ")\n",
    "victimas.select(\"anio\",\"valor\").summary().show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "laboratorio8",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
